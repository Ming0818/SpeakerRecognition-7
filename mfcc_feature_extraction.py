#__author__ = 'naminpark'
'''
file name should be generated by speaker index
example : 1_xxx.wav, 1_yyy.wav -> two files are from same speaker
the discriminator is a number written in file name
'''
import os
import librosa
import numpy as np
import csv
import pickle
from sklearn.mixture import GaussianMixture
from qbgmm import *
import copy



class data_RW:
    '''
    global variables
    '''
    n_class=15
    res=[]
    n_mfcc = 20
    n_feature=0
    dataX=[]
    dataY=[]
    _index=0
    component=1

    def __init__(self):

        pass


    """
    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.
    : x: List of sample Labels
    : return: Numpy array of one-hot encoded labels
    """
    def one_hot_encode(self,x, n_classes):
        #return np.eye(n_classes)[x.astype(np.int)]
        ote= np.eye(n_classes+1)[x.astype(np.int)]
        return ote[:,0:-1]

    def setVariable(self,n_mfcc,n_class,component):
        self.n_class=n_class
        self.n_mfcc=n_mfcc
        self.component = component



    def csvWrite(self,filename,arr,fmt):
        np.savetxt(filename,arr,delimiter=',',fmt=fmt)

    def csvRead(self,filename):
        arr=np.loadtxt(filename,delimiter=',')
        return arr

    @classmethod
    def shuffle(cls,feat,label):
        perm=np.random.permutation(len(label))
        return feat[perm],label[perm]


    def featureExtract(self,type,path):

        for root, dirs, files in os.walk(path):
            for file in files:
                if os.path.splitext(file)[1].lower() == '.wav':
                    filepath = os.path.join(root, file)
                    self.res.append(filepath)
        '''
        :param n_mfcc: how many feature extracted for mfcc?
        :param type:  what kind of feature type you want?
               ex) type == 1: fixed feature per file
               ex) type == 2: dynamic feature
        :return: data , corresponding label
        '''
        '''
        :param n_mfcc:
        :param type:
        :return:
        '''
        f=open('test.pickle','rb')
        ubm=pickle.load(f)
        f.close()
        if type == 1:
            self.n_feature =  self.n_mfcc*2*self.component #+ (n_mfcc*2)**2

            trainX=np.zeros((1,self.n_feature))
            trainY=np.zeros(1)

            for i, filename in enumerate(self.res):
                #basis_model = copy.deepcopy(ubm)
                gmm=GaussianMixture(self.component, covariance_type='diag')  # 'full','tied','diag','spherical'

                y, sr = librosa.load(filename,sr=8000)

                '''
                # feature extraction mfcc-13, delta-13
                # mean and covariance for mfcc
                '''
                from python_speech_features import mfcc
                from python_speech_features import delta

                mfcc_feat = mfcc(y,samplerate=sr,numcep=self.n_mfcc,winlen=0.025,winstep=0.005)
                mfcc_delta = delta(mfcc_feat, 2)

                mfcc_feat = mfcc_feat.T
                mfcc_delta = mfcc_delta.T

                #mfcc_mean = np.mean(mfcc_feat,axis=1)
                #mfcc_mean=mfcc_mean.reshape([len(mfcc),1])
                #mfcc_feat= mfcc_feat-mfcc_mean
                #mfcc_delta_mean = np.mean(mfcc_delta,axis=1)
                #mfcc_feat=np.concatenate((mfcc_mean,mfcc_delta_mean),axis=0)
                #mfcc_feat=mfcc_feat.reshape(1,len(mfcc_feat))
                #feat=np.concatenate((mfcc_feat,mfcc_delta),axis=0)
                #cov=np.corrcoef(feat)
                #cov=np.cov(feat)
                #tmp=cov.reshape(1,len(cov)**2)

                feat=np.concatenate((mfcc_feat,mfcc_delta),axis=0)

                #feat_gmm=gmm_map_qb(feat.T, basis_model)

                feat_gmm=gmm.fit(feat.T)

                supervector=[]
                for j in range(self.component):
                    supervector = np.hstack((supervector,feat_gmm.means_[j]))
                supervector = supervector.reshape(1,self.n_feature)

                trainX=np.vstack((trainX,supervector)) #np.vstack((trainX,np.hstack((mfcc_feat,tmp))))
                '''
                The modification is nessesary to use for speaker number.
                '''
                splitfilename=filename.split('/')
                label=int(splitfilename[-1].split('_')[0])

                trainY=np.hstack((trainY,label))

                print "processing no. file: %d" %(i)


            self.dataX = trainX[1:]
            trainY = trainY[1:] -1
            self.dataY = self.one_hot_encode(trainY,self.n_class)

        elif type ==2:

            from python_speech_features import mfcc
            from python_speech_features import delta

            frame_len=11
            self.n_feature = (self.n_mfcc*2)*frame_len

            trainX=np.zeros((1,self.n_feature))
            trainY=np.zeros(1)

            for i, filename in enumerate(self.res):
                y, sr = librosa.load(filename,sr=8000)

                '''
                # feature extraction mfcc-13, delta-13
                # mean and covariance for mfcc
                librosa mfcc array: feature size by frame length
                '''
                mfcc_feat = mfcc(y,sr,numcep=self.n_mfcc,winlen=0.025,winstep=0.01)
                mfcc_delta = delta(mfcc_feat, 2)

                mfcc_feat = mfcc_feat.T
                mfcc_delta = mfcc_delta.T

                #mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=self.n_mfcc)
                #mfcc_mean = np.mean(mfcc,axis=1)
                #mfcc_mean=mfcc_mean.reshape([len(mfcc),1])
                #mfcc= mfcc-mfcc_mean

                #mfcc_delta = librosa.feature.delta(mfcc)

                feat=np.concatenate((mfcc_feat,mfcc_delta),axis=0)
                # feat size 26 by frame length

                #frame_len=len(feat)
                #Here, n_mfcc means frame size
                #feat=feat.T
                #tmp=feat[:-(feat.shape[0]%frame_len)].T
                #tmp=tmp.reshape([-1,self.n_feature])

                tran_feat=feat.T
                tmp=np.zeros((len(tran_feat)-frame_len,1))
                for j in range(frame_len):
                    tmp=np.hstack((tmp,tran_feat[j:j+len(tran_feat)-frame_len]))

                feat_group = tmp[:,1:]

                #tmp : frame length by 26

                #tmp=feat[:-(feat.shape[0]%frame_len)].T

                trainX=np.vstack((trainX,feat_group))

                '''
                The modification is nessesary to use for speaker number.
                '''
                splitfilename=filename.split('/')

                label=int(splitfilename[-1].split('_')[0])

                num_label=np.zeros(feat_group.shape[0])
                num_label = num_label+label
                trainY=np.hstack((trainY,num_label))

                print "processing no. file: %d" %(i)

            self.dataX = trainX[1:]
            trainY = trainY[1:] -1
            self.dataY = self.one_hot_encode(trainY,self.n_class)

        return self.dataX, self.dataY

    def setValue(self,X,Y):
        self.dataX=X
        self.dataY=Y

    def next_batch(self,itr,batch_size):

        self._index = (itr * batch_size) % (self.dataY.shape[0] - batch_size)
        X = self.dataX[self._index:(self._index + batch_size)]
        Y = self.dataY[self._index:(self._index + batch_size)]
        return X, Y

    def UBM_TRAIN(self,path):
        res=[]
        for root, dirs, files in os.walk(path):
            for file in files:
                if os.path.splitext(file)[1].lower() == '.wav':
                    filepath = os.path.join(root, file)
                    res.append(filepath)

        self.n_feature =  self.n_mfcc*2

        trainX=np.zeros((1,self.n_feature))

        ubm=GaussianMixture(self.component, covariance_type='diag')  # 'full','tied','diag','spherical'

        for i, filename in enumerate(res):
            y, sr = librosa.load(filename,sr=8000)

            '''
            # feature extraction mfcc-13, delta-13
            # mean and covariance for mfcc
            '''
            from python_speech_features import mfcc
            from python_speech_features import delta

            mfcc_feat = mfcc(y,samplerate=sr,numcep=self.n_mfcc,winlen=0.025,winstep=0.005)
            mfcc_delta = delta(mfcc_feat, 2)

            mfcc_feat = mfcc_feat.T
            mfcc_delta = mfcc_delta.T

            #mfcc_mean = np.mean(mfcc_feat,axis=1)
            #mfcc_mean=mfcc_mean.reshape([len(mfcc),1])
            #mfcc_feat= mfcc_feat-mfcc_mean
            #mfcc_delta_mean = np.mean(mfcc_delta,axis=1)
            #mfcc_feat=np.concatenate((mfcc_mean,mfcc_delta_mean),axis=0)
            #mfcc_feat=mfcc_feat.reshape(1,len(mfcc_feat))
            #feat=np.concatenate((mfcc_feat,mfcc_delta),axis=0)
            #cov=np.corrcoef(feat)
            #cov=np.cov(feat)
            #tmp=cov.reshape(1,len(cov)**2)

            feat=np.concatenate((mfcc_feat,mfcc_delta),axis=0)
            trainX=np.vstack((trainX,feat.T)) #np.vstack((trainX,np.hstack((mfcc_feat,tmp))))


            print "processing no. file: %d" %(i)

        feat_ubm=ubm.fit(trainX[1:])
        f=open('test.pickle','wb')
        pickle.dump(feat_ubm,f)
        f.close()






if __name__=="__main__":

    path = './VAD/TRAIN_dependant/'

    DR=data_RW()

    GMix=1
    n_mfcc =20
    n_class =15

    isTrainforUBM = False #True
    #isTrainforUBM = True

    DR.setVariable(n_mfcc,n_class,GMix)

    if isTrainforUBM == True:
        ubm=DR.UBM_TRAIN('./VAD/TRAIN/')

    else:
        tX, tY=DR.featureExtract(1,path)
        tfeat,tlabel=DR.shuffle(tX,tY)

        DR.csvWrite(path+"input_feat_TRAIN.csv",tfeat,'%f')
        DR.csvWrite(path+"input_label_TRAIN.csv",tlabel,'%d')

        #feat = DR.csvRead(path+"input_feat.csv")
        #label= DR.csvRead(path+"input_label.csv")



